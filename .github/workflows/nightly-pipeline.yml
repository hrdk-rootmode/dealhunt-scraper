name: ðŸŒ™ Nightly Scrape & AI Processing

on:
  # Manual trigger with options
  workflow_dispatch:
    inputs:
      scrape_limit:
        description: 'Products per platform (default: 1000)'
        required: false
        default: '1000'
        type: string
      skip_scraping:
        description: 'Skip scraping (run AI only)'
        required: false
        default: false
        type: boolean
      skip_ai:
        description: 'Skip AI processing (scrape only)'
        required: false
        default: false
        type: boolean
  
  # Run daily at 2:00 AM IST (8:30 PM UTC previous day)
  schedule:
    - cron: '30 20 * * *'

env:
  NODE_VERSION: '18'
  SCRAPE_LIMIT: ${{ github.event.inputs.scrape_limit || '1000' }}

jobs:
  # ==================== JOB 1: SCRAPING ====================
  scrape:
    name: ðŸ•·ï¸ Scrape Products
    runs-on: ubuntu-latest
    if: ${{ github.event.inputs.skip_scraping != 'true' }}
    timeout-minutes: 90
    
    outputs:
      total_products: ${{ steps.scrape.outputs.total_products }}
      platforms_scraped: ${{ steps.scrape.outputs.platforms_scraped }}
      
    steps:
      - name: ðŸ“¥ Checkout code
        uses: actions/checkout@v4
      
      - name: ðŸ“¦ Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
      
      - name: ðŸ“š Install dependencies
        run: npm ci
      
      - name: ðŸ•·ï¸ Run Multi-Platform Scraper
        id: scrape
        env:
          DATABASE_URL: ${{ secrets.DATABASE_URL }}
          REDIS_URL: ${{ secrets.REDIS_URL }}
          SCRAPE_LIMIT: ${{ env.SCRAPE_LIMIT }}
        run: |
          echo "ðŸš€ Starting scraper..."
          echo "ðŸ“¦ Target: $SCRAPE_LIMIT products per platform"
          echo ""
          node src/scripts/scrape-all-platforms.js

  # ==================== JOB 2: AI PROCESSING ====================
  ai-process:
    name: ðŸ¤– AI Processing
    runs-on: ubuntu-latest
    needs: scrape
    if: |
      always() && 
      (needs.scrape.result == 'success' || needs.scrape.result == 'skipped') &&
      github.event.inputs.skip_ai != 'true'
    timeout-minutes: 60
    
    steps:
      - name: ðŸ“¥ Checkout code
        uses: actions/checkout@v4
      
      - name: ðŸ“¦ Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
      
      - name: ðŸ“š Install dependencies
        run: npm ci
      
      - name: ðŸ¤– Run AI Processing
        id: ai
        env:
          DATABASE_URL: ${{ secrets.DATABASE_URL }}
          REDIS_URL: ${{ secrets.REDIS_URL }}
          GROQ_API_KEY: ${{ secrets.GROQ_API_KEY }}
          AI_BATCH_SIZE: '100'
          AI_MAX_PRODUCTS: '2000'
          NODE_ENV: production
        run: |
          echo "ðŸ¤– Starting AI processing..."
          node src/ai/process-products-groq.js

  # ==================== JOB 3: SUMMARY ====================
  summary:
    name: ðŸ“Š Pipeline Summary
    runs-on: ubuntu-latest
    needs: [scrape, ai-process]
    if: always()
    
    steps:
      - name: ðŸ“Š Generate Summary
        run: |
          echo "# ðŸª DealHunt Nightly Pipeline" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## ðŸ“… Run Details" >> $GITHUB_STEP_SUMMARY
          echo "| Property | Value |" >> $GITHUB_STEP_SUMMARY
          echo "|----------|-------|" >> $GITHUB_STEP_SUMMARY
          echo "| Date | $(date -u '+%Y-%m-%d %H:%M UTC') |" >> $GITHUB_STEP_SUMMARY
          echo "| Run ID | ${{ github.run_id }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Trigger | ${{ github.event_name }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Products/Platform | ${{ env.SCRAPE_LIMIT }} |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          echo "## ðŸ“‹ Results" >> $GITHUB_STEP_SUMMARY
          echo "| Stage | Status |" >> $GITHUB_STEP_SUMMARY
          echo "|-------|--------|" >> $GITHUB_STEP_SUMMARY
          
          if [ "${{ needs.scrape.result }}" == "success" ]; then
            echo "| ðŸ•·ï¸ Scraping | âœ… Success |" >> $GITHUB_STEP_SUMMARY
          elif [ "${{ needs.scrape.result }}" == "skipped" ]; then
            echo "| ðŸ•·ï¸ Scraping | â­ï¸ Skipped |" >> $GITHUB_STEP_SUMMARY
          else
            echo "| ðŸ•·ï¸ Scraping | âŒ Failed |" >> $GITHUB_STEP_SUMMARY
          fi
          
          if [ "${{ needs.ai-process.result }}" == "success" ]; then
            echo "| ðŸ¤– AI Processing | âœ… Success |" >> $GITHUB_STEP_SUMMARY
          elif [ "${{ needs.ai-process.result }}" == "skipped" ]; then
            echo "| ðŸ¤– AI Processing | â­ï¸ Skipped |" >> $GITHUB_STEP_SUMMARY
          else
            echo "| ðŸ¤– AI Processing | âŒ Failed |" >> $GITHUB_STEP_SUMMARY
          fi
          
          echo "" >> $GITHUB_STEP_SUMMARY
          
          if [ "${{ needs.scrape.result }}" == "success" ] && [ "${{ needs.ai-process.result }}" == "success" ]; then
            echo "## âœ… Pipeline Completed Successfully!" >> $GITHUB_STEP_SUMMARY
          elif [ "${{ needs.scrape.result }}" == "skipped" ] && [ "${{ needs.ai-process.result }}" == "success" ]; then
            echo "## âœ… AI Processing Completed!" >> $GITHUB_STEP_SUMMARY
          else
            echo "## âš ï¸ Pipeline Completed with Issues" >> $GITHUB_STEP_SUMMARY
            echo "Check the logs above for details." >> $GITHUB_STEP_SUMMARY
          fi